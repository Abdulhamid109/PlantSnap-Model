{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required Python packages\n",
        "!pip install fastapi uvicorn nest_asyncio python-multipart\n",
        "\n",
        "# # Download and install cloudflared\n",
        "# !wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "# !dpkg -i cloudflared-linux-amd64.deb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9TEiIu1xrma",
        "outputId": "3adf0214-c944-4dc3-d49e-f18597aa31cf"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.115.6)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.34.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (0.0.20)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.41.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.10.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/plant_classification_AM_model.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWj_UjzbJ7HW",
        "outputId": "829a9e87-2d14-4600-ae14-bb5b71eda47d"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/plant_classification_AM_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show fastapi uvicorn nest_asyncio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDJ12HOZ1BFx",
        "outputId": "ec2a8100-5ae5-42c5-aab7-f8ca1c0b778b"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: fastapi\n",
            "Version: 0.115.6\n",
            "Summary: FastAPI framework, high performance, easy to learn, fast to code, ready for production\n",
            "Home-page: https://github.com/fastapi/fastapi\n",
            "Author: \n",
            "Author-email: =?utf-8?q?Sebasti=C3=A1n_Ram=C3=ADrez?= <tiangolo@gmail.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: pydantic, starlette, typing-extensions\n",
            "Required-by: gradio\n",
            "---\n",
            "Name: uvicorn\n",
            "Version: 0.34.0\n",
            "Summary: The lightning-fast ASGI server.\n",
            "Home-page: https://www.uvicorn.org/\n",
            "Author: \n",
            "Author-email: Tom Christie <tom@tomchristie.com>, Marcelo Trylesinski <marcelotryle@gmail.com>\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: click, h11, typing-extensions\n",
            "Required-by: gradio\n",
            "---\n",
            "Name: nest-asyncio\n",
            "Version: 1.6.0\n",
            "Summary: Patch asyncio to allow nested event loops\n",
            "Home-page: https://github.com/erdewit/nest_asyncio\n",
            "Author: Ewald R. de Wit\n",
            "Author-email: ewald.de.wit@gmail.com\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: nbclassic, notebook, orbax-checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cloudflared --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaTJE3OERFTb",
        "outputId": "89b369bd-44c1-4fc4-ff29-a64371423b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cloudflared version 2024.12.2 (built 2024-12-19-1724 UTC)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0CcR1u9nMSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819df69f-a125-4c7c-b4bc-a75c70d0c804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-110' coro=<Server.serve() done, defined at /usr/local/lib/python3.10/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/main.py\", line 579, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 66, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 315, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 69, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 142, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-113' coro=<Server.serve() done, defined at /usr/local/lib/python3.10/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/main.py\", line 579, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 66, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 315, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 69, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 142, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-116' coro=<Server.serve() done, defined at /usr/local/lib/python3.10/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/main.py\", line 579, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 66, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 315, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 232, in __step\n",
            "    result = coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 69, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 142, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:     Started server process [350]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [350]\n"
          ]
        }
      ],
      "source": [
        "# from fastapi import FastAPI, File, UploadFile\n",
        "# from fastapi.middleware.cors import CORSMiddleware\n",
        "# from tensorflow.keras.models import load_model\n",
        "# from tensorflow.keras.preprocessing import image\n",
        "# import numpy as np\n",
        "# import io\n",
        "# from PIL import Image\n",
        "# import nest_asyncio\n",
        "# import uvicorn\n",
        "# import os\n",
        "\n",
        "# app = FastAPI()\n",
        "\n",
        "# # Enable CORS for all origins (for Flutter)\n",
        "# app.add_middleware(\n",
        "#     CORSMiddleware,\n",
        "#     allow_origins=[\"*\"],  # Allows all origins\n",
        "#     allow_credentials=True,\n",
        "#     allow_methods=[\"*\"],  # Allows all methods\n",
        "#     allow_headers=[\"*\"],  # Allows all headers\n",
        "# )\n",
        "\n",
        "# # Load model (you can also use a pre-trained model if preferred)\n",
        "# MODEL_PATH = '/content/plant_classification_AM_model.h5'\n",
        "# model = load_model(MODEL_PATH)\n",
        "# class_labels = ['aloevera', 'banana', 'bilimbi', 'cantaloupe', 'cassava', 'coconut', 'corn', 'cucumber', 'curcuma', 'eggplant', 'galangal', 'ginger', 'guava', 'kale', 'longbeans', 'mango', 'melon', 'orange', 'paddy', 'papaya', 'peperchili', 'pineapple', 'pomelo', 'shallot', 'soybeans', 'spinach', 'sweetpotatoes', 'tobacco', 'waterapple', 'watermelon']\n",
        "\n",
        "# @app.post(\"/predict/\")\n",
        "# async def predict(file: UploadFile = File(...)):\n",
        "#     try:\n",
        "#         contents = await file.read()\n",
        "#         img = Image.open(io.BytesIO(contents)).convert(\"RGB\")\n",
        "#         img = img.resize((224, 224))\n",
        "#         img_array = np.array(img) / 255.0\n",
        "#         img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "#         predictions = model.predict(img_array)\n",
        "#         predicted_class = np.argmax(predictions, axis=1)[0]\n",
        "#         confidence = float(np.max(predictions))\n",
        "\n",
        "#         return {\n",
        "#             \"success\": True,\n",
        "#             \"class\": class_labels[predicted_class],\n",
        "#             \"confidence\": confidence,\n",
        "#             \"error\": None\n",
        "#         }\n",
        "#     except Exception as e:\n",
        "#         return {\n",
        "#             \"success\": False,\n",
        "#             \"class\": None,\n",
        "#             \"confidence\": None,\n",
        "#             \"error\": str(e)\n",
        "#         }\n",
        "\n",
        "# # Run the app on 0.0.0.0 to make it accessible outside the local environment\n",
        "# if __name__ == \"__main__\":\n",
        "#     nest_asyncio.apply()\n",
        "#     uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cloudflared tunnel --url http://localhost:8000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YfR17_bWbm5",
        "outputId": "50434096-ad3b-4b3e-d033-87f8554b9d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2025-01-03T04:09:47Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-01-03T04:09:47Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m |  https://perceived-counties-wisdom-poison.trycloudflare.com                                |\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m Version 2024.12.2 (Checksum 5237675a5e806120729acc78c5be02f9db5f406717699587abfa72b49b39fe40)\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.22.5, GoArch: amd64\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 protocol:quic url:http://localhost:8000]\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 903c6103-7c52-4e34-88d9-7544290aad93\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update if installed by a package manager.\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "2025/01/03 04:09:51 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-01-03T04:09:51Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m36530975-50e1-443d-a03a-25c294d33fea \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113 \u001b[36mlocation=\u001b[0mlax01 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2025-01-03T04:10:17Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2025-01-03T04:10:17Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "\u001b[90m2025-01-03T04:10:17Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.113\n",
            "\u001b[90m2025-01-03T04:10:17Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2025-01-03T04:10:17Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2025-01-03T04:10:17Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2r6KpO70VAhXZI07dX01CkM1B9B_3Q9xNV3X2RrYSraoiyxjm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3DLfTfeYzyK",
        "outputId": "f6fa5c8b-39df-4bc0-b105-2b1d6169d2a1"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"Public URL: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY7CV4pRW4w-",
        "outputId": "b8fd358a-340a-4355-e34d-135f01eb9a20"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Public URL: NgrokTunnel: \"https://98f0-34-125-129-218.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, File, UploadFile, HTTPException, Request\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import JSONResponse\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import threading\n",
        "import time\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# CORS middleware configuration\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Load model (as in your original code)\n",
        "MODEL_PATH = '/content/plant_classification_AM_model.h5'\n",
        "model = None\n",
        "class_labels = [\n",
        "    'aloevera', 'banana', 'bilimbi', 'cantaloupe', 'cassava', 'coconut',\n",
        "    'corn', 'cucumber', 'curcuma', 'eggplant', 'galangal', 'ginger',\n",
        "    'guava', 'kale', 'longbeans', 'mango', 'melon', 'orange', 'paddy',\n",
        "    'papaya', 'peperchili', 'pineapple', 'pomelo', 'shallot', 'soybeans',\n",
        "    'spinach', 'sweetpotatoes', 'tobacco', 'waterapple', 'watermelon'\n",
        "]\n",
        "\n",
        "# @app.post(\"/upload/\")\n",
        "# async def upload_file(file: UploadFile = File(...)):\n",
        "#     \"\"\"\n",
        "#     Test endpoint for file upload only\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         contents = await file.read()\n",
        "#         return JSONResponse({\n",
        "#             \"filename\": file.filename,\n",
        "#             \"content_type\": file.content_type,\n",
        "#             \"size\": len(contents)\n",
        "#         })\n",
        "#     except Exception as e:\n",
        "#         raise HTTPException(status_code=400, detail=str(e))\n",
        "\n",
        "@app.post(\"/predict/\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    \"\"\"\n",
        "    Main prediction endpoint\n",
        "    \"\"\"\n",
        "    if not file:\n",
        "        raise HTTPException(status_code=400, detail=\"No file uploaded\")\n",
        "\n",
        "    try:\n",
        "        # Read file\n",
        "        contents = await file.read()\n",
        "        if not contents:\n",
        "            raise HTTPException(status_code=400, detail=\"Empty file\")\n",
        "\n",
        "        # Load model if needed\n",
        "        global model\n",
        "        if model is None:\n",
        "            model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "        # Process image\n",
        "        img = Image.open(io.BytesIO(contents)).convert('RGB')\n",
        "        img = img.resize((224, 224))\n",
        "        img_array = np.array(img) / 255.0\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        # Make prediction\n",
        "        predictions = model.predict(img_array)\n",
        "        predicted_class = np.argmax(predictions, axis=1)[0]\n",
        "        confidence = float(np.max(predictions))\n",
        "\n",
        "        return JSONResponse({\n",
        "            \"success\": True,\n",
        "            \"predicted_class\": class_labels[predicted_class],\n",
        "            \"confidence\": confidence\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.get(\"/test/\")\n",
        "async def test():\n",
        "    \"\"\"\n",
        "    Test endpoint\n",
        "    \"\"\"\n",
        "    return {\"status\": \"working\"}\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"Server is running\"}\n",
        "\n",
        "@app.options(\"/upload/\")\n",
        "async def options_upload():\n",
        "    return {\"message\": \"OPTIONS request handled\"}\n",
        "\n",
        "@app.post(\"/upload/\")\n",
        "async def debug_upload(request: Request):\n",
        "    try:\n",
        "        # Print request headers for debugging\n",
        "        print(\"Request headers:\", dict(request.headers))\n",
        "\n",
        "        form = await request.form()\n",
        "        print(\"Form data received:\", form)\n",
        "\n",
        "        if \"file\" not in form:\n",
        "            return JSONResponse(\n",
        "                status_code=400,\n",
        "                content={\"error\": \"No file field in request\"}\n",
        "            )\n",
        "\n",
        "        file = form[\"file\"]\n",
        "        if not isinstance(file, UploadFile):\n",
        "            return JSONResponse(\n",
        "                status_code=400,\n",
        "                content={\"error\": \"Invalid file upload\"}\n",
        "            )\n",
        "\n",
        "        contents = await file.read()\n",
        "\n",
        "        return JSONResponse({\n",
        "            \"success\": True,\n",
        "            \"filename\": file.filename,\n",
        "            \"content_type\": file.content_type,\n",
        "            \"size\": len(contents)\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing upload: {str(e)}\")\n",
        "        return JSONResponse(\n",
        "            status_code=500,\n",
        "            content={\"error\": f\"Server error: {str(e)}\"}\n",
        "        )\n",
        "\n",
        "\n",
        "# Ngrok setup\n",
        "def run_ngrok():\n",
        "    public_url = ngrok.connect(8000)\n",
        "    print(f\"Public URL: {public_url}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    nest_asyncio.apply()\n",
        "\n",
        "    # Start ngrok in a separate thread\n",
        "    tunnel_thread = threading.Thread(target=run_ngrok, daemon=True)\n",
        "    tunnel_thread.start()\n",
        "    time.sleep(5)  # Wait for ngrok to start\n",
        "\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecnNmImIawBD",
        "outputId": "35145fd8-acc9-41e3-a36a-d0715cacf48a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://16f0-34-125-129-218.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [350]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     2409:40c2:5051:bc69:ed09:21c3:36ee:b3dc:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     2409:40c2:5051:bc69:ed09:21c3:36ee:b3dc:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "Request headers: {'host': '16f0-34-125-129-218.ngrok-free.app', 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36', 'content-length': '0', 'accept': 'application/json', 'accept-encoding': 'gzip, deflate, br, zstd', 'accept-language': 'en-US,en;q=0.8', 'cookie': 'abuse_interstitial=16f0-34-125-129-218.ngrok-free.app', 'origin': 'https://16f0-34-125-129-218.ngrok-free.app', 'priority': 'u=1, i', 'referer': 'https://16f0-34-125-129-218.ngrok-free.app/docs', 'sec-ch-ua': '\"Brave\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"', 'sec-ch-ua-mobile': '?0', 'sec-ch-ua-platform': '\"Windows\"', 'sec-fetch-dest': 'empty', 'sec-fetch-mode': 'cors', 'sec-fetch-site': 'same-origin', 'sec-gpc': '1', 'x-forwarded-for': '2409:40c2:5051:bc69:ed09:21c3:36ee:b3dc', 'x-forwarded-host': '16f0-34-125-129-218.ngrok-free.app', 'x-forwarded-proto': 'https'}\n",
            "Error processing upload: The `python-multipart` library must be installed to use form parsing.\n",
            "INFO:     2409:40c2:5051:bc69:ed09:21c3:36ee:b3dc:0 - \"POST /upload/ HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     2409:40c2:5051:bc69:ed09:21c3:36ee:b3dc:0 - \"POST /predict/ HTTP/1.1\" 400 Bad Request\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-01-03T05:37:13+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8000-ef52bc05-01de-4d17-bb59-53daf0559e35 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-01-03T05:37:13+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8000-ef52bc05-01de-4d17-bb59-53daf0559e35 err=\"failed to start tunnel: session closed\"\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [350]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M8lBeQFilHq2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}